<!DOCTYPE html>
<html lang="en">

<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<!-- Bootstrap core CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
	<!-- https://fontawesome.com/cheatsheet -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
	<!-- Custom styles for this template -->
	<link rel="stylesheet" href="css/style.css">
    <script src="js/main.js"></script>
    <script src="js/scroll.js"></script>
    <meta name="keywords" content="Boubacar Diallo, Deep Learning, Computer Vision, Machine, Learning, Artificial Intelligence"> 
	<meta name="description" content="Personal page of Boubacar Diallo">
</head>

<title>Boubacar DIALLO</title>

<body>
	<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark" id="Home">
		<div class="container">
		<a class="navbar-brand" href="index.html">R&D Engineer in DATA | IA - VISION | ROBOTICS | Specialized LLMs</a>
		<div class="collapse navbar-collapse" id="navbarToggle">
			<ul class="navbar-nav ml-auto">
				<li class="nav-item">
					<a class="nav-link" href="index.html">Home</a>
				</li>
				<!-- <li class="nav-item">
					<a class="nav-link" href="lab.html">Lab</a>
				</li> -->
				<li class="nav-item">
					<a class="nav-link" href="publication.html">Publication</a>
				</li>
				<!-- <li class="nav-item">
					<a class="nav-link" href="award.html">Award</a>
				</li> -->
				<li class="nav-item">
					<a class="nav-link" href="experiences_exr.html">Role@ExR</a>
				</li>
				<li class="nav-item">
					<a class="nav-link" href="talk.html">Tutorials</a>
				</li>
				<li class="nav-item">
					<a class="nav-link" href="more.html">CV</a>
				</li>
			</ul>
		</div>
		</div>
	</nav>

	<div class="container" style="padding-top: 20px; font-size: 17px">
		<div class="row">
			<div class="col-md-3", style="padding-right: 0px; padding-top: 0px">
				<img class="img-responsive img-rounded" src="picture/boubacardiallo2.png" alt="" style="max-width: 220px; solid black"><br>
			</div>
			<div class="col-md-5", style="padding-right: 40px; padding-top: 0px">
				<h2>Boubacar DIALLO Ph.D.</h2>
				<p>
					<b><font color="black">Senior AI-Vision R&D Engineer at Exxact Robotics</font></b><br>
					<b><font color="black">Ph.D. in AI and CV from Poitiers University</font></b><br>
					<b><font color="black">CEO of TTV</font></b> : <i><u>Technology into value</u></i><br>
					<b>Address:</b> 25 Avenue de Middelkerke, <br>
					51200 √âpernay, France<br>
					<b>Phone:</b> +33 (0)6 63 21 17 13<br>
					<b>Email:</b> <a href="boubacar.diallo.perso[at]gmail.com">boubacar.diallo.perso@gmail.com</a><br><br>

					<a href="https://scholar.google.com/citations?user=u2yppEsAAAAJ&hl" target="_blank"><font color="black"><i class="ai ai-google-scholar ai-lg"></i></font></a>&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
					<a href="https://github.com/boubacardiallo20" target="_blank"><font color="black"><i class="fab fa-github fa-lg"></i></font></a>&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
					<a href="https://x.com/DialloBoubaAI" target="_blank"><font color="black"><i class="fab fa-twitter fa-lg"></i></font></a> &nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
					<a href="https://sfa.univ-poitiers.fr/" target="_blank">
						<img src="picture/logo/poitiers.png" alt="Precision Agriculture" class="img-fluid" style="width: 10%;">
					</a>&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
					<a href="https://www.xlim.fr/" target="_blank">
						<img src="picture/logo/xlim.png" alt="Generative Modeling" class="img-fluid" style="width: 10%;">
					</a>&nbsp;&nbsp;&nbsp;/&nbsp;&nbsp;
					<a href="https://exxact-robotics.com/en/" target="_blank">
						<img src="picture/logo/exr.png" alt="Autonomous Systems" class="img-fluid" style="width: 15%;">
					</a>
				</p>
			</div>
			<div class="col-md-4", style="padding-right: 40px; padding-top: 15px">
                <font color="black"><h5><b>Research Interests:</b></h5>
					<ul>
						<li><a><i>AI - Computer Vision</i></a></li>
						<li><a><i>Visual scene Understanding</i></a></li>
						<li><a><i>LLM and Multimodal Learning</i></a></li>
						<li><a><i>Perception / Autonomous Driving</i></a></li>
						<li><a><i>Robot Learning and Embodied AI</i></a></li>
						<li><a><i>Precision Agriculture and Robotics</i></a></li>
						<li><a><i>Generative Modeling (synthetic data)</i></a></li>
					</ul>
				</font>
			</div>
		</div>
		
		<div class="row">
			<div class="col-md-12">
			<p>
				<div style="text-align:justify">I was a Senior AI R&D Engineer in the AI/Vision Team at 
					<a href="experiences_exr.html">Exxact Robotics</a>, 
					where we focused on innovative solutions for precision agriculture. 
					My current research interests and directions were centered on advancing AI to address real-world challenges, 
					particularly in the domains of precision agriculture, robotics, and autonomous systems. They included: </div>
			</p>
			<p>
				<div style="text-align:justify">
					<li><a><i>Comprehensive Strategy for data collection, annotation, and analysis across images, text, and videos.</i></a></li> 
					<li><a><i>Creation and Deployment of Robust AI Models for Precision Agriculture and Robotics.</i></a></li> 
					<li><a><i>Visual scene understanding, perception, reconstruction, representation learning, multimodal learning.</i></a></li> 
					<li><a><i>Generative modeling, creation, generation and manipulation of visual content (synthetic images/3D).</i></a></li> 
					<li><a><i>Autonomous driving, Embodied AI, Robotic Learning, RL and LLM applications, etc...</i></a></li>
			</p>
			<div style="text-align:justify; padding: 10px; border: 1px solid #ee8e8e; border-radius: 5px; background-color: #f9f9f9;">
				<b>Experience at Exxact Robotics : </b>
				I have 4+ years of professional experience working with deep learning systems, 
				data analysis, and robot learning at Exxact Robotics from Jan. 2021 to Feb. 2025. 
				<a href="experiences_exr.html">You can discover HERE all the tasks performed !</a>
			</div>
			<!-- <br> -->
			<hr>
			<p>
				<div style="text-align:justify">
					Previously, I had the pleasure of working as a Doctoral Researcher (Ph.D.) in the ICONES team of the 
					<a href="https://www.xlim.fr/recherche/pole-mathematiques-informatique-image/synthese-analyse-dimages">ASALI Axis</a> 
					within <a href="https://www.xlim.fr/">XLIM UMR CNRS</a>, - Multidisciplinary Research Institute, 
					<a href="https://sfa.univ-poitiers.fr/">University of Poitiers</a>. 
					My research focused on <a href="https://theses.fr/2020POIT2293"><i><u>Image Integrity Measurement: 
						From Physical Models to Deep Learning Models</u></i></a>, under the supervision of 
						<a href="https://xlim-sic.labo.univ-poitiers.fr/maloigne/">Prof. Christine Fernandez</a>, 
						<a href="https://xlim-sic.labo.univ-poitiers.fr/turruty/">Assoc. Prof. Thierry Urruty</a>, 
						and <a href="https://xlim-sic.labo.univ-poitiers.fr/pbourdon/">Assoc. Prof. Pascal Bourdon</a>. 
				</div>
			</p>
			<p>
				<div style="text-align:justify">
					Before starting my Ph.D., I gained valuable experience as a Research Intern at the XLIM laboratory, 
					where I collaborated with <a href="https://xlim-sic.labo.univ-poitiers.fr/perrine/">Assoc. Prof. Clency Perrine</a> 
					on the project <i><u>Implementation of a Software-Defined Radio Platform: Application to PAPR Reduction</u></i>.
				</div>
			</p>
			</div>
		</div>
	</div>

	<hr>

  <!-- News -->
    <h3 id="Expertise" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;">Expertise in Data Analysis - AI Model Development and Deployment</h3>
	<div style="text-align:justify; padding: 10px; border: 1px solid #fd805a; border-radius: 5px; background-color: #e5faf9;">
		<div class="container" style="padding-top: 20px; font-size: 17px">
			<h5><b>General Expertise</b></h5>
			<ul>
				<li>PhD-level experience in relevant fields such as Computer Vision, Machine Learning, AI and Data Engineering.</li>
				<li>Strong ability to conduct independent research and collaborate effectively in a team-oriented environment.</li>
				<li>Proven experience in model workflow, model development, Fine-tuning, and evaluation with large-scale neural networks.</li>
				<li>Proficiency in Python with experience in machine learning frameworks like PyTorch, JAX, or similar.</li>
				<li>Experience working with large codebases on GitHub and distributed computing environments.</li>
			</ul>
			
			<h5><b>Data Processing and Evaluation</b></h5>
			<ul>
				<li>Experience with scalable data engineering toolchains such as SQL, Pandas, NumPy, and FiftyOne for image dataset processing.</li>
				<li>Design and build data and evaluation pipelines and perform training of multi-task deep neural networks.</li>
				<li>Analyze large-scale learning datasets using queries and data processing scripts (analyzing, augmenting, and transforming the data).</li>
				<li>Collaborate with data/annotation engineers to develop automated data pipelines with the FiftyOne App.</li>
				<li>Integrate AI models to automate manual tasks (pre-annotation, active learning tools) while maintaining high data quality.</li>
				<li>Work closely with agronomists and annotation engineers to support new model architectures and dataset requirements.</li>
			</ul>
			
			<h5><b>AI Model Lifecycle and Deployment</b></h5>
			<ul>
				<li>Collaborate with other engineers from product teams to align model development with company goals.</li>
				<li>Ownership of the full model development lifecycle, from data preparation to real-world deployment.</li>
				<li>Develop and implemented novel approaches to model fine-tuning, optimization, and evaluation.</li>
				<li>White-box understanding of deep learning: model details, loss formulations, and training algorithms.</li>
				<li>Design and conduct experiments to better understand model behavior and to identify and mitigate risks.</li>
				<li>Work with cross-functional teams to deploy AI solutions in real-world applications.</li> 
				<li>Experience in NN deployment toolchains (ONNX) and techniques such as TensorRT, model quantization/pruning.</li>
			</ul>
			
			<h5><b>Robotics and Simulation</b></h5>
			<ul>
				<li>Experience working with robotic learning systems using simulation tools</li>
				<li>Experience with some physical simulators (e.g. Mujoco, IsaacSim, IsaacLab)</li>
				<li>Passionate about building robot learning systems.</li>
			</ul>
			
			<h5><b>Cloud Infrastructure and AI Scalability</b></h5>
			<ul>
				<li>Experience managing cloud infrastructure with GCP and AWS (Instances, Bucket).</li>
				<li>Familiarity with job scheduling/orchestration tools such as Kubernetes (MLFlow, Kubeflow, ZenML).</li>
			</ul>
			
			<h5><b>AI Safety and Robustness</b></h5>
			<ul>
				<li>Ability to develop novel computer vision models for tasks such as classification, object detection, and segmentation.</li>
				<li>Familiarity with AI safety and robustness challenges in real-world environments (e.g., precision agriculture, real-time applications).</li>
				<li>Understanding of fundamental geometric concepts in computer vision, including perspective transformation and epipolar geometry.</li>
				<li>Thrive in a high pace environment, where solutions are often unclear and require exploration.</li>
			</ul>
		</div>
	</div>

	<hr>

	<div style="text-align:justify; padding: 10px; border: 1px solid #e9cbcb; border-radius: 5px; background-color: #f9f9f9;">
		<p>
			<div style="text-align:justify">üíûÔ∏è I am passionate about collaborating on projects that have a positive impact on humanity and the planet. 
				With over ten publications covering topics such as deep learning, digital image tampering detection, artificial intelligence applied 
				to precision agriculture, and image processing, I strive to contribute meaningfully to these evolving field.</div>
		</p>
		<p>
			<div style="text-align:justify">üìñ <b>Educator:</b> In addition to my research activities, I am actively engaged in training the next 
				generation of innovators. I design and publish online courses and offer tutorials to disseminate the latest advances and applications 
				in my field, thus helping to make knowledge accessible and inspire future talents.</div>
		</p>
	</div>

	<!-- Publications -->
	<div class="container" style="padding-top: 20px; font-size: 17px;">
		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;">My Publications</h3>
		<p><a href="https://scholar.google.com/citations?user=u2yppEsAAAAJ&hl">Google Scholar</a> and <a href="publication.html">Full List</a>.</p>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2025</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">Thesis Defense</div>
			<img class="img-fluid img-rounded" src="teaser/bouba/thesis2025.jpeg"></div>
			<div class="col-md-9">
			<u>Thesis Supervision:</u> <b><font color="black">Conformal Prediction for Vision-Based Decision-Making in Agriculture</font></b><br>
			Melki, P., Bombrun, L., <b>Diallo Boubacar</b>, Dias, J., & Da Costa, J. P.<br>
			<a href="https://theses.fr/s346234">Defense of the thesis in June 2025</a>
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Over the course of nearly two and a half years, I had the opportunity to supervise Paul Melki‚Äôs CIFRE PhD thesis, 
				entitled "Contributions to Conformal Prediction for Vision-Based Decision-Making in Agriculture," 
				in collaboration with the IMS Laboratory in Universit√© de Bordeaux and EXXACT Robotics.<br>
				
				Working with Paul has always been a real pleasure, filled with rich moments of scientific reflection. 
				I hope that this work will be well recognized by the community and that we have made a meaningful 
				contribution in our own way.

			</i></div>
            </div>
		</div>

		<hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ArXiv</div><img class="img-fluid img-rounded" src="teaser/bouba/conformal_2025.png"></div>
			<div class="col-md-9">
			<b><font color="black">Uncertainty Guarantees on Automated Precision Weeding using Conformal Prediction</font></b><br>
			Melki, P., Bombrun, L., <b>Diallo Boubacar</b>, Dias, J., & Da Costa, J. P.<br>
			arXiv preprint arXiv:2501.07185, 2025. 
			[<a href="https://arxiv.org/pdf/2501.07185">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				After a detailed presentation of the conformal prediction methodology and the development of a precision spraying pipeline 
				based on a ''conformalized'' neural network and well-defined spraying decision rules, the article evaluates this pipeline 
				on two real-world scenarios: one under in-distribution conditions, the other reflecting a near out-of-distribution setting.
			</i></div>
            </div>
		</div><br>
		
		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2024</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">CVPR</div><img class="img-fluid img-rounded" src="teaser/bouba/repip.png"></div>
			<div class="col-md-9">
			<b><font color="black">The Penalized Inverse Probability Measure for Conformal Classification</font></b><br>
			Melki, P., Bombrun, L., <b>Diallo Boubacar</b>, Dias, J., & Da Costa, J. P.<br>
			In Proceedings of the Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024. 
			[<a href="https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/papers/Melki_The_Penalized_Inverse_Probability_Measure_for_Conformal_Classification_CVPRW_2024_paper.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Through toy examples and empirical results on the task of crop and weed image classification in agricultural robotics, 
				the current work shows how PIP-based conformal classifiers exhibit precisely the desired behavior in comparison with 
				other nonconformity measures and strike a good balance between informativeness and efficiency.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ArXiv</div><img class="img-fluid img-rounded" src="teaser/bouba/AL2024.png"></div>
			<div class="col-md-9">
			<b><font color="black">Active learning for efficient annotation in precision agriculture: A use-case on crop-weed semantic segmentation.</font></b><br>
			van Marrewijk, B. M., Dandjinou, C., Rustia, D. J. A., Gonzalez, N. F., <b>Diallo Boubacar</b> & Blok, P. M..<br>
			(<b>ICCV 2023</b>) - <b>ArXiv</b> preprint arXiv:2404.02580, 2024. [<a href="https://arxiv.org/pdf/2404.02580">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				This study addresses this research gap by conducting a comparative study of three active learning-based acquisition functions: 
				Bayesian Active Learning by Disagreement (BALD), stochastic-based BALD (PowerBALD), and Random. 
				The acquisition functions were tested on two agricultural datasets: Sugarbeet and Corn-Weed, both containing 
				three semantic classes: background, crop and weed.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2023</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">AgriTech</div><img class="img-fluid img-rounded" src="teaser/bouba/impact.png"></div>
			<div class="col-md-9">
			<b><font color="black">Impact of the Environmental Conditions on the Robustness of a Weed Detection Model</font></b><br>
			Nicolas Franco Gonzalez, Paul Melki, <b>Boubacar Diallo</b>, Hugo Antoine, Estelle Millet.<br>
			AgriTech Day (<b>SIMA</b>), 2023. 
			[<a href="https://agritechday.com/wp-content/uploads/2022/12/AGRITECHDAY_CONFERENCE_PROCEEDINGS_2022.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				The main contribution of this article is the proposal of a methodology for analyzing the impact of this variability 
				on weed detection quality. We focus only on four intrinsic and external factors that contribute to the variability 
				of conditions (which we call meta-variables) : the vegetation development stage (using the BBCH scale), the soil 
				characteristics, namely its color and humidity level, and the condition of the sky at the moment of image acquisition (sunny or overcast).
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ICCV</div><img class="img-fluid img-rounded" src="teaser/bouba/aps2023_0.png"></div>
			<div class="col-md-9">
			<b><font color="black">Group-Conditional Conformal Prediction via Quantile Regression Calibration for Crop and Weed Classification</font></b><br>
			Paul Melki, Lionel Bombrun, <b>Boubacar Diallo</b>, J√©r√¥me Dias, Jean-Pierre Da Costa<br>
			Proceedings of the IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023. 
			[<a href="https://openaccess.thecvf.com/content/ICCV2023W/CVPPA/papers/Melki_Group-Conditional_Conformal_Prediction_via_Quantile_Regression_Calibration_for_Crop_and_ICCVW_2023_paper.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				This article presents the conformal prediction framework that provides valid statistical guarantees on 
				the predictive performance of any black box prediction machine, with almost no assumptions, 
				applied to the problem of deep visual classification of weeds and crops in real-world conditions.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ICCV Poster</div><img class="img-fluid img-rounded" src="teaser/bouba/AL2024.png"></div>
			<div class="col-md-9">
			<b><font color="black">Active learning for efficient annotation in crop-weed semantic segmentation.</font></b><br>
			Blok, P. M., van Marrewijk, B. M., <b>Boubacar Diallo</b>, Dandjinou, C., Gonzalez, N. F., Melki, P., ... & Dias, J.<br>
			Proceedings of the IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023. 
			[<a href="https://cvppa2023.github.io/assets/38.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				In agriculture, datasets tend to contain more redundant images and imbalanced classes. 
				Therefore, in this research the added value of active learning was tested on a Corn-Weed dataset. 
				Three acquisition functions were compared: BALD, PowerBALD and Random. 
				Both BALD and PowerBALD outperformed Random sampling even when 90.9% of the pixels belonged to the background class.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2022</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">CEA: Elsevier</div><img class="img-fluid img-rounded" src="teaser/bouba/maskal.png"></div>
			<div class="col-md-9">
			<b><font color="black">
				Active learning with MaskAL reduces annotation effort for training Mask R-CNN on a broccoli dataset with visually similar classes
			</font></b><br>
			Pieter M Blok, Gert Kootstra, Hakim Elchaoui Elghor, <b>Boubacar Diallo</b>, Frits K van Evert, E. van Henten.<br>
			Computers and Electronics in Agriculture,  Elsevier (<b>CEA: Elsevier</b>), 2022. 
			[<a href="https://www.sciencedirect.com/science/article/pii/S0168169922002344">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				The goal of our work was to reduce the number of annotated images needed to train a CNN while maintaining its performance. 
				We use an active learning method capable of automatically selecting difficult-to-classify images and based on the Mask R-CNN 
				instance segmentation algorithm and named this method MaskAL.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">GRETSI</div><img class="img-fluid img-rounded" src="teaser/bouba/explo_2022.png"></div>
			<div class="col-md-9">
			<b><font color="black">Analyse exploratoire de m√©triques en segmentation d'images: application en proxid√©tection</font></b><br>
			Melki, P., Bombrun, L., Millet, E., <b>Boubacar Diallo</b>, Elghor, H. E., & da Costa, J. P.<br>
			In Groupe d'Etudes du Traitement du Signal et des Images (<b>GRETSI</b>), 2022.
			[<a href="https://www.mdpi.com/2072-4292/14/4/996">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Working in an agricultural context, specifically on the problem of the automatic detection of plants in proximal 
				sensing images, we studied twelve evaluation metrics that we used to evaluate three image segmentation models 
				recently presented in the literature. After a unified presentation of these metrics, we carried out an exploratory 
				analysis of their relationships using a correlation analysis, a clustering of variables, and two factorial analyses 
				(namely principal component analysis and multiple factorial analysis). .
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2020</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">Ph.D Report</div>
			<img class="img-fluid img-rounded" src="teaser/bouba/thesis.png"></div>
			<div class="col-md-9">
			<b><font color="black">Mesure de l'int√©grit√© d'une image : des mod√®les physiques aux mod√®les d'apprentissage profond</font></b><br>
			<b>Boubacar Diallo</b>, HAL science ouverte, December 2020. [<a href="https://hal.science/tel-03212896v1">Paper</a>]<br>
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				In this thesis, we focus on several of these image forensic challenges including camera
				model identification and image tampering detection. After reviewing the state of the
				art in the field, we propose a first data-driven method for identifying camera models.
				We use deep learning techniques based on convolutional neural networks (CNNs)
				and develop a learning strategy considering the quality of the input data versus the
				applied transformation. A family of CNN networks has been designed to learn the
				characteristics of the camera model directly from a collection of images undergoing
				the same transformations as those commonly used on the Internet.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">FSI</div><img class="img-fluid img-rounded" src="teaser/bouba/robustness.png"></div>
			<div class="col-md-9">
			<b><font color="black">Robust forgery detection for compressed images using CNN supervision</font></b><br>
			<b>Boubacar Diallo</b>, Thierry Urruty, Pascal Bourdon, Christine Fernandez-Maloigne.<br>
			Forensic Science International: Reports (<b>FSI: Reports</b>), 2020.
			[<a href="https://www.sciencedirect.com/science/article/pii/S266591072030061X?ref=pdf_download&fr=RR-2&rr=8e200e4d499c6ed2">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				This article presents a framework improving robustness for image forgery detection. 
				The most important step of our framework is to take into account the image quality corresponding 
				to the chosen application. Therefore, we relied on a camera identification model based on convolutional 
				neural networks.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2019</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">MMM</div><img class="img-fluid img-rounded" src="teaser/bouba/mmm2019.png"></div>
			<div class="col-md-9">
			<b><font color="black">Improving robustness of image tampering detection for compression</font></b><br>
			<b>Boubacar Diallo</b>, Thierry Urruty, Pascal Bourdon, Christine Fernandez-Maloigne.<br>
			MultiMedia Modeling: 25th International Conference (<b>MMM</b>), 2019. 
			[<a href="https://hal.science/hal-02401565/file/Paper_MMM2019.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Improving the robustness of tampered image detection algorithms is essential for compression manipulation 
				as it is the most common type of post-processing on the Internet.
            </i></div>
			</div>
		</div><hr>

	</div><br>
	<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>
</body>
</html>