<!DOCTYPE html>
<html lang="en">

<head>
	<!-- Required meta tags -->
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
	<!-- Bootstrap core CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta/css/bootstrap.min.css" integrity="sha384-/Y6pD6FV/Vv2HJnA6t+vslU6fwYXjCFtcEpHbNJ0lyAFsXTsjBbfaDjzALeQsN6M" crossorigin="anonymous">
	<!-- https://fontawesome.com/cheatsheet -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css">
	<!-- Custom styles for this template -->
	<link rel="stylesheet" href="css/style.css">
	<!-- <link rel="icon" href="picture/hku.png"> -->
    <script src="js/main.js"></script>
    <script src="js/scroll.js"></script>
    <meta name="keywords" content="Boubacar Diallo, Deep Learning, Computer Vision, Machine, Learning, Artificial Intelligence"> 
	<meta name="description" content="Personal page of Boubacar Diallo">
</head>

<title>Boubacar DIALLO</title>

<body>
	<nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark" id="Home">
		<div class="container">
		<a class="navbar-brand" href="index.html">Boubacar DIALLO</a>
		<div class="collapse navbar-collapse" id="navbarToggle">
			<ul class="navbar-nav ml-auto">
				<li class="nav-item">
					<a class="nav-link" href="index.html">Home</a>
				</li>
				<!-- <li class="nav-item">
					<a class="nav-link" href="lab.html">Lab</a>
				</li> -->
				<!-- <li class="nav-item">
					<a class="nav-link" href="publication.html">Publication</a>
				</li> -->
				<!-- <li class="nav-item">
					<a class="nav-link" href="award.html">Award</a>
				</li> -->
				<li class="nav-item">
					<a class="nav-link" href="experiences_exr.html">Role@ExR</a>
				</li>
				<li class="nav-item">
					<a class="nav-link" href="talk.html">Tutorials</a>
				</li>
				<li class="nav-item">
					<a class="nav-link" href="more.html">CV</a>
				</li>
			</ul>
		</div>
		</div>
	</nav>

	<!-- Publications -->
	<div class="container" style="padding-top: 20px; font-size: 17px;">
		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;">Selected Publications</h3>
		<p><li class="nav-item">From <a href="http://scholar.google.com/citations?user=u2yppEsAAAAJ&hl">Google Scholar...</a></li></p>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2025</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">ArXiv</div><img class="img-fluid img-rounded" src="teaser/bouba/conformal_2025.png"></div>
			<div class="col-md-9">
			<b><font color="black">Uncertainty Guarantees on Automated Precision Weeding using Conformal Prediction</font></b><br>
			Melki, P., Bombrun, L., <b>Diallo Boubacar</b>, Dias, J., & Da Costa, J. P.<br>
			arXiv preprint arXiv:2501.07185, 2025. 
			[<a href="https://arxiv.org/pdf/2501.07185">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				After a detailed presentation of the conformal prediction methodology and the development of a precision spraying pipeline 
				based on a ''conformalized'' neural network and well-defined spraying decision rules, the article evaluates this pipeline 
				on two real-world scenarios: one under in-distribution conditions, the other reflecting a near out-of-distribution setting.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2024</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">CVPR</div><img class="img-fluid img-rounded" src="teaser/bouba/repip.png"></div>
			<div class="col-md-9">
			<b><font color="black">The Penalized Inverse Probability Measure for Conformal Classification</font></b><br>
			Melki, P., Bombrun, L., <b>Diallo Boubacar</b>, Dias, J., & Da Costa, J. P.<br>
			In Proceedings of the Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2024. 
			[<a href="https://openaccess.thecvf.com/content/CVPR2024W/SAIAD/papers/Melki_The_Penalized_Inverse_Probability_Measure_for_Conformal_Classification_CVPRW_2024_paper.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Through toy examples and empirical results on the task of crop and weed image classification in agricultural robotics, 
				the current work shows how PIP-based conformal classifiers exhibit precisely the desired behavior in comparison with 
				other nonconformity measures and strike a good balance between informativeness and efficiency.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ArXiv</div><img class="img-fluid img-rounded" src="teaser/bouba/AL2024.png"></div>
			<div class="col-md-9">
			<b><font color="black">Active learning for efficient annotation in precision agriculture: A use-case on crop-weed semantic segmentation.</font></b><br>
			van Marrewijk, B. M., Dandjinou, C., Rustia, D. J. A., Gonzalez, N. F., <b>Diallo Boubacar</b> & Blok, P. M..<br>
			(<b>ICCV 2023</b>) - <b>ArXiv</b> preprint arXiv:2404.02580, 2024. [<a href="https://arxiv.org/pdf/2404.02580">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				This study addresses this research gap by conducting a comparative study of three active learning-based acquisition functions: 
				Bayesian Active Learning by Disagreement (BALD), stochastic-based BALD (PowerBALD), and Random. 
				The acquisition functions were tested on two agricultural datasets: Sugarbeet and Corn-Weed, both containing 
				three semantic classes: background, crop and weed.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2023</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">AgriTech</div><img class="img-fluid img-rounded" src="teaser/bouba/impact.png"></div>
			<div class="col-md-9">
			<b><font color="black">Impact of the Environmental Conditions on the Robustness of a Weed Detection Model</font></b><br>
			Nicolas Franco Gonzalez, Paul Melki, <b>Boubacar Diallo</b>, Hugo Antoine, Estelle Millet.<br>
			AgriTech Day (<b>SIMA</b>), 2023. 
			[<a href="https://agritechday.com/wp-content/uploads/2022/12/AGRITECHDAY_CONFERENCE_PROCEEDINGS_2022.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				The main contribution of this article is the proposal of a methodology for analyzing the impact of this variability 
				on weed detection quality. We focus only on four intrinsic and external factors that contribute to the variability 
				of conditions (which we call meta-variables) : the vegetation development stage (using the BBCH scale), the soil 
				characteristics, namely its color and humidity level, and the condition of the sky at the moment of image acquisition (sunny or overcast).
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ICCV</div><img class="img-fluid img-rounded" src="teaser/bouba/aps2023_0.png"></div>
			<div class="col-md-9">
			<b><font color="black">Group-Conditional Conformal Prediction via Quantile Regression Calibration for Crop and Weed Classification</font></b><br>
			Paul Melki, Lionel Bombrun, <b>Boubacar Diallo</b>, Jérôme Dias, Jean-Pierre Da Costa<br>
			Proceedings of the IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023. 
			[<a href="https://openaccess.thecvf.com/content/ICCV2023W/CVPPA/papers/Melki_Group-Conditional_Conformal_Prediction_via_Quantile_Regression_Calibration_for_Crop_and_ICCVW_2023_paper.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				This article presents the conformal prediction framework that provides valid statistical guarantees on 
				the predictive performance of any black box prediction machine, with almost no assumptions, 
				applied to the problem of deep visual classification of weeds and crops in real-world conditions.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">ICCV Poster</div><img class="img-fluid img-rounded" src="teaser/bouba/AL2024.png"></div>
			<div class="col-md-9">
			<b><font color="black">Active learning for efficient annotation in crop-weed semantic segmentation.</font></b><br>
			Blok, P. M., van Marrewijk, B. M., <b>Boubacar Diallo</b>, Dandjinou, C., Gonzalez, N. F., Melki, P., ... & Dias, J.<br>
			Proceedings of the IEEE/CVF International Conference on Computer Vision (<b>ICCV</b>), 2023. 
			[<a href="https://cvppa2023.github.io/assets/38.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				In agriculture, datasets tend to contain more redundant images and imbalanced classes. 
				Therefore, in this research the added value of active learning was tested on a Corn-Weed dataset. 
				Three acquisition functions were compared: BALD, PowerBALD and Random. 
				Both BALD and PowerBALD outperformed Random sampling even when 90.9% of the pixels belonged to the background class.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2022</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">CEA: Elsevier</div><img class="img-fluid img-rounded" src="teaser/bouba/maskal.png"></div>
			<div class="col-md-9">
			<b><font color="black">
				Active learning with MaskAL reduces annotation effort for training Mask R-CNN on a broccoli dataset with visually similar classes
			</font></b><br>
			Pieter M Blok, Gert Kootstra, Hakim Elchaoui Elghor, <b>Boubacar Diallo</b>, Frits K van Evert, E. van Henten.<br>
			Computers and Electronics in Agriculture,  Elsevier (<b>CEA: Elsevier</b>), 2022. 
			[<a href="https://www.sciencedirect.com/science/article/pii/S0168169922002344">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				The goal of our work was to reduce the number of annotated images needed to train a CNN while maintaining its performance. 
				We use an active learning method capable of automatically selecting difficult-to-classify images and based on the Mask R-CNN 
				instance segmentation algorithm and named this method MaskAL.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">GRETSI</div><img class="img-fluid img-rounded" src="teaser/bouba/explo_2022.png"></div>
			<div class="col-md-9">
			<b><font color="black">Analyse exploratoire de métriques en segmentation d'images: application en proxidétection</font></b><br>
			Melki, P., Bombrun, L., Millet, E., <b>Boubacar Diallo</b>, Elghor, H. E., & da Costa, J. P.<br>
			In Groupe d'Etudes du Traitement du Signal et des Images (<b>GRETSI</b>), 2022.
			[<a href="https://www.mdpi.com/2072-4292/14/4/996">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Working in an agricultural context, specifically on the problem of the automatic detection of plants in proximal 
				sensing images, we studied twelve evaluation metrics that we used to evaluate three image segmentation models 
				recently presented in the literature. After a unified presentation of these metrics, we carried out an exploratory 
				analysis of their relationships using a correlation analysis, a clustering of variables, and two factorial analyses 
				(namely principal component analysis and multiple factorial analysis). .
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2020</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">Ph.D Report</div>
			<img class="img-fluid img-rounded" src="teaser/bouba/thesis.png"></div>
			<div class="col-md-9">
			<b><font color="black">Mesure de l'intégrité d'une image : des modèles physiques aux modèles d'apprentissage profond</font></b><br>
			<b>Boubacar Diallo</b>, HAL science ouverte, December 2020. [<a href="https://hal.science/tel-03212896v1">Paper</a>]<br>
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				In this thesis, we focus on several of these image forensic challenges including camera
				model identification and image tampering detection. After reviewing the state of the
				art in the field, we propose a first data-driven method for identifying camera models.
				We use deep learning techniques based on convolutional neural networks (CNNs)
				and develop a learning strategy considering the quality of the input data versus the
				applied transformation. A family of CNN networks has been designed to learn the
				characteristics of the camera model directly from a collection of images undergoing
				the same transformations as those commonly used on the Internet.
			</i></div>
            </div>
		</div><hr>

		<div class="row">
			<div class="col-md-3"><div class="badge">FSI</div><img class="img-fluid img-rounded" src="teaser/bouba/robustness.png"></div>
			<div class="col-md-9">
			<b><font color="black">Robust forgery detection for compressed images using CNN supervision</font></b><br>
			<b>Boubacar Diallo</b>, Thierry Urruty, Pascal Bourdon, Christine Fernandez-Maloigne.<br>
			Forensic Science International: Reports (<b>FSI: Reports</b>), 2020.
			[<a href="https://www.sciencedirect.com/science/article/pii/S266591072030061X?ref=pdf_download&fr=RR-2&rr=8e200e4d499c6ed2">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				This article presents a framework improving robustness for image forgery detection. 
				The most important step of our framework is to take into account the image quality corresponding 
				to the chosen application. Therefore, we relied on a camera identification model based on convolutional 
				neural networks.
			</i></div>
            </div>
		</div><br>

		<h3 id="Publications" style="padding-top: 80px; margin-top: -80px; margin-left: -18px;"><b>2019</b></h3>
		<hr>
		<div class="row">
			<div class="col-md-3"><div class="badge">MMM</div><img class="img-fluid img-rounded" src="teaser/bouba/mmm2019.png"></div>
			<div class="col-md-9">
			<b><font color="black">Improving robustness of image tampering detection for compression</font></b><br>
			<b>Boubacar Diallo</b>, Thierry Urruty, Pascal Bourdon, Christine Fernandez-Maloigne.<br>
			MultiMedia Modeling: 25th International Conference (<b>MMM</b>), 2019. 
			[<a href="https://hal.science/hal-02401565/file/Paper_MMM2019.pdf">Paper</a>]
			<div style="text-align:justify; color: rgb(107, 105, 105);"><i>
				Improving the robustness of tampered image detection algorithms is essential for compression manipulation 
				as it is the most common type of post-processing on the Internet.
            </i></div>
			</div>
		</div><hr>

	</div><br>
	
	<script>var scroll = new SmoothScroll('a[href*="#"]', {speed: 1000});</script>
</body>
</html>